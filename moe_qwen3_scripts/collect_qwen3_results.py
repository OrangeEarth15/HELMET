#!/usr/bin/env python3
"""
æ”¶é›†Qwen3-30B-A3B-Instruct MoE XAT attentionæ–¹æ¡ˆçš„HELMETè¯„ä¼°ç»“æžœ
ä¸“é—¨ç”¨äºŽæ±‡æ€»Qwen3-30B MoEçš„full, xattn, flex, xflexç­‰attentionæœºåˆ¶çš„ç»“æžœ
"""

import os
import sys
import json
import numpy as np
import pandas as pd
import yaml
from dataclasses import dataclass, asdict
from tqdm import tqdm

# æ·»åŠ HELMETæ ¹ç›®å½•åˆ°è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
helmet_root = os.path.dirname(script_dir)
sys.path.append(helmet_root)

# å¯¼å…¥collect_resultsçš„åŸºç¡€ç±»å’Œå‡½æ•°
from scripts.collect_results import arguments, dataset_to_metrics, custom_avgs

def main():
    """æ”¶é›†Qwen3-30B MoE XAT attentionç»“æžœ"""
    
    # ðŸŽ¯ Qwen3-30B MoE XAT Attentioné…ç½®
    qwen3_moe_configs = [
        # Full FlashInfer Attention
        {"model": "Qwen3-30B-A3B-Instruct", "tag": "qwen3_moe_full_flashinfer", 
         "output_dir": "moe_qwen3_output/full_flashinfer", "attention": "full"},
        
        # XAttention - é€‚åˆ30B MoEçš„threshold
        {"model": "Qwen3-30B-A3B-Instruct", "tag": "qwen3_moe_xattn_threshold0.9", 
         "output_dir": "moe_qwen3_output/xattn_threshold0.9", "attention": "xattn", "threshold": 0.9},
        {"model": "Qwen3-30B-A3B-Instruct", "tag": "qwen3_moe_xattn_threshold0.95", 
         "output_dir": "moe_qwen3_output/xattn_threshold0.95", "attention": "xattn", "threshold": 0.95},
        
        # XFlex - MoEä¼˜åŒ–é…ç½®
        {"model": "Qwen3-30B-A3B-Instruct", "tag": "qwen3_moe_xflex_threshold0.95_scoreratio0.95", 
         "output_dir": "moe_qwen3_output/xflex_threshold0.95_scoreratio0.95", "attention": "xflex", 
         "threshold": 0.95, "score_ratio": 0.95},
        {"model": "Qwen3-30B-A3B-Instruct", "tag": "qwen3_moe_xflex_threshold0.9_scoreratio0.9", 
         "output_dir": "moe_qwen3_output/xflex_threshold0.9_scoreratio0.9", "attention": "xflex", 
         "threshold": 0.9, "score_ratio": 0.9},
    ]

    # ðŸ“‹ æ•°æ®é›†é…ç½®æ–‡ä»¶
    config_files = [
        "configs/recall.yaml", "configs/recall_short.yaml", 
        "configs/rag.yaml", "configs/rag_short.yaml", 
        "configs/longqa.yaml", "configs/longqa_short.yaml", 
        "configs/summ.yaml", "configs/summ_short.yaml", 
        "configs/rerank.yaml", "configs/rerank_short.yaml", 
        "configs/icl.yaml", "configs/icl_short.yaml", 
        "configs/cite.yaml", "configs/cite_short.yaml", 
    ]

    # è§£æžæ•°æ®é›†é…ç½®
    dataset_configs = []
    
    for file in config_files:
        config_path = os.path.join(helmet_root, file)
        if not os.path.exists(config_path):
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            continue
            
        c = yaml.safe_load(open(config_path))
        
        if isinstance(c["generation_max_length"], int):
            c["generation_max_length"] = ",".join([str(c["generation_max_length"])] * len(c["datasets"].split(",")))
        for d, t, l, g in zip(c['datasets'].split(','), c['test_files'].split(','), c['input_max_length'].split(','), c['generation_max_length'].split(',')):
            # å¤„ç†ç©ºçš„test_files
            if t.strip() == '':
                test_name = ''
            else:
                test_name = os.path.basename(os.path.splitext(t)[0])
            
            # åŒ…å«æ‰€æœ‰é•¿åº¦é…ç½®
            input_len = int(l.strip())
            dataset_configs.append({
                "dataset": d.strip(), 
                "test_name": test_name, 
                "input_max_length": input_len, 
                "generation_max_length": int(g.strip()), 
                "max_test_samples": c['max_test_samples'], 
                'use_chat_template': c['use_chat_template'], 
                'shots': c['shots']
            })

    print(f"ðŸ“Š æ‰¾åˆ° {len(dataset_configs)} ä¸ªæ•°æ®é›†é…ç½®")
    print(f"ðŸŽ¯ å°†å¤„ç† {len(qwen3_moe_configs)} ä¸ªQwen3-30B MoE XAT attentioné…ç½®")

    # æ”¶é›†ç»“æžœ
    failed_paths = []
    df = []
    
    for config in tqdm(qwen3_moe_configs, desc="æ”¶é›†Qwen3-30B MoE XATç»“æžœ"):
        args = arguments()
        args.tag = config["tag"]
        args.output_dir = config["output_dir"]
        args.model = config["model"]
        
        print(f"\nðŸ“ å¤„ç†é…ç½®: {config['attention']} - {config['tag']}")
        print(f"   è¾“å‡ºç›®å½•: {args.output_dir}")
        
        # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(args.output_dir):
            print(f"âš ï¸ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {args.output_dir}")
            continue
        
        config_found_results = 0
        for dataset in dataset_configs:
            args.update(dataset)
            
            metric = args.get_averaged_metric()
            dsimple, mnames = args.get_metric_name()

            if metric is None:
                failed_paths.append(args.get_path())
                continue
                
            config_found_results += 1
            for k, m in metric.items():
                df.append({
                    **asdict(args), 
                    **config,
                    "metric name": k, 
                    "metric": m, 
                    "dataset_simple": dsimple + " " + k, 
                    "test_data": f"{args.dataset}-{args.test_name}-{args.input_max_length}"
                })
        
        print(f"   âœ… æ‰¾åˆ° {config_found_results} ä¸ªæœ‰æ•ˆç»“æžœ")

    if not df:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆç»“æžœï¼è¯·æ£€æŸ¥:")
        print("   1. è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨")
        print("   2. tagåç§°æ˜¯å¦æ­£ç¡®")
        print("   3. æ˜¯å¦æœ‰å®Œæˆçš„è¯„ä¼°ä»»åŠ¡")
        print("   4. æ˜¯å¦éœ€è¦è¿è¡ŒGPT-4è¯„ä¼°")
        return

    # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
    print(f"\nðŸ“ˆ ç”Ÿæˆæ±‡æ€»è¡¨æ ¼...")
    all_df = pd.DataFrame(df)
    
    # åˆ›å»ºé€è§†è¡¨
    lf_df = all_df.pivot_table(
        index=["input_max_length", "attention", "tag"], 
        columns="dataset_simple", 
        values="metric", 
        sort=False
    )
    lf_df = lf_df.reset_index()

    # è®¡ç®—è‡ªå®šä¹‰å¹³å‡å€¼
    for k, v in custom_avgs.items():
        available_cols = [col for col in v if col in lf_df.columns]
        if available_cols:
            lf_df[k] = lf_df[available_cols].mean(axis=1)
        else:
            print(f"âš ï¸ è·³è¿‡ {k}: ç¼ºå°‘å¿…è¦çš„åˆ—")

    # ä¿å­˜ç»“æžœ
    output_file = os.path.join(helmet_root, "qwen3_moe_results_summary.csv")
    lf_df.to_csv(output_file, index=False)
    
    print(f"âœ… ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"ðŸ“Š å…±å¤„ç†äº† {len(df)} ä¸ªæ•°æ®ç‚¹")
    
    # æ˜¾ç¤ºé¢„è§ˆ
    print("\nðŸ“‹ ç»“æžœé¢„è§ˆ:")
    available_custom_cols = [col for col in custom_avgs.keys() if col in lf_df.columns]
    if available_custom_cols:
        print(lf_df[['input_max_length', 'attention', 'tag'] + available_custom_cols].to_string(index=False))

    if failed_paths:
        print(f"\nâš ï¸ ä»¥ä¸‹ {len(failed_paths)} ä¸ªè·¯å¾„çš„ç»“æžœæœªæ‰¾åˆ°:")
        for path in failed_paths[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"   {path}")
        if len(failed_paths) > 10:
            print(f"   ... è¿˜æœ‰ {len(failed_paths)-10} ä¸ª")

    return lf_df, failed_paths

if __name__ == "__main__":
    main()
